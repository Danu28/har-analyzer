name: Code Quality

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run weekly on Sundays
    - cron: '0 2 * * 0'

jobs:
  code-quality:
    name: Code Quality Analysis
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install quality tools
      run: |
        python -m pip install --upgrade pip
        pip install black isort flake8 mypy pylint bandit safety
        pip install -r requirements.txt
    
    - name: Code formatting with Black
      run: |
        echo "::group::Black Formatting Check"
        black --check --diff --color .
        echo "::endgroup::"
    
    - name: Import sorting with isort
      run: |
        echo "::group::Import Sorting Check"
        isort --check-only --diff --color .
        echo "::endgroup::"
    
    - name: Linting with flake8
      run: |
        echo "::group::Flake8 Linting"
        flake8 . --count --statistics --format='::error file=%(path)s,line=%(row)d,col=%(col)d::%(path)s:%(row)d:%(col)d: %(code)s %(text)s'
        echo "::endgroup::"
    
    - name: Type checking with mypy
      run: |
        echo "::group::MyPy Type Checking"
        mypy . --ignore-missing-imports --show-error-codes || true
        echo "::endgroup::"
      continue-on-error: true
    
    - name: Advanced linting with pylint
      run: |
        echo "::group::Pylint Analysis"
        pylint scripts/ demo_*.py --output-format=text --reports=no --score=no || true
        echo "::endgroup::"
      continue-on-error: true
    
    - name: Security analysis with bandit
      run: |
        echo "::group::Security Analysis"
        bandit -r . -f json -o bandit-report.json
        bandit -r . -f txt
        echo "::endgroup::"
      continue-on-error: true
    
    - name: Dependency vulnerability check
      run: |
        echo "::group::Dependency Security Check"
        safety check --file requirements.txt --output json --save-json safety-report.json || true
        safety check --file requirements.txt
        echo "::endgroup::"
      continue-on-error: true
    
    - name: Code complexity analysis
      run: |
        echo "::group::Code Complexity Analysis"
        python -c "
        import ast
        import os
        
        def analyze_complexity(filepath):
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    tree = ast.parse(f.read())
                
                functions = [node for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]
                classes = [node for node in ast.walk(tree) if isinstance(node, ast.ClassDef)]
                
                print(f'{filepath}: {len(functions)} functions, {len(classes)} classes')
                
                # Check for long functions (>50 lines)
                for func in functions:
                    lines = func.end_lineno - func.lineno if hasattr(func, 'end_lineno') else 0
                    if lines > 50:
                        print(f'  ⚠️  Long function: {func.name} ({lines} lines)')
                
            except Exception as e:
                print(f'Error analyzing {filepath}: {e}')
        
        # Analyze Python files
        for root, dirs, files in os.walk('.'):
            # Skip .git and __pycache__
            dirs[:] = [d for d in dirs if not d.startswith('.') and d != '__pycache__']
            
            for file in files:
                if file.endswith('.py'):
                    filepath = os.path.join(root, file)
                    analyze_complexity(filepath)
        "
        echo "::endgroup::"
    
    - name: Documentation quality check
      run: |
        echo "::group::Documentation Quality"
        python -c "
        import os
        import re
        
        def check_docstrings(filepath):
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Check for module docstring
                if not re.search(r'^\s*[\"\"\"\'\'\']{3}', content.lstrip()):
                    print(f'{filepath}: Missing module docstring')
                
                # Check function docstrings
                functions = re.findall(r'def\s+(\w+)\s*\([^)]*\):', content)
                docstrings = re.findall(r'def\s+\w+\s*\([^)]*\):\s*\n\s*[\"\"\"\'\'\']{3}', content)
                
                if len(functions) > len(docstrings):
                    missing = len(functions) - len(docstrings)
                    print(f'{filepath}: {missing} functions missing docstrings')
                
            except Exception as e:
                print(f'Error checking {filepath}: {e}')
        
        print('Checking documentation quality...')
        for root, dirs, files in os.walk('.'):
            dirs[:] = [d for d in dirs if not d.startswith('.') and d != '__pycache__']
            for file in files:
                if file.endswith('.py') and not file.startswith('test_'):
                    filepath = os.path.join(root, file)
                    check_docstrings(filepath)
        "
        echo "::endgroup::"
    
    - name: Performance metrics
      run: |
        echo "::group::Performance Metrics"
        python -c "
        import os
        import subprocess
        import time
        
        def get_file_metrics():
            total_lines = 0
            total_files = 0
            
            for root, dirs, files in os.walk('.'):
                dirs[:] = [d for d in dirs if not d.startswith('.') and d != '__pycache__']
                for file in files:
                    if file.endswith('.py'):
                        filepath = os.path.join(root, file)
                        try:
                            with open(filepath, 'r', encoding='utf-8') as f:
                                lines = len(f.readlines())
                                total_lines += lines
                                total_files += 1
                                print(f'{filepath}: {lines} lines')
                        except:
                            pass
            
            print(f'\\nTotal: {total_files} Python files, {total_lines} lines of code')
            print(f'Average: {total_lines // total_files if total_files > 0 else 0} lines per file')
        
        get_file_metrics()
        "
        echo "::endgroup::"
    
    - name: Upload quality reports
      uses: actions/upload-artifact@v3
      with:
        name: quality-reports
        path: |
          bandit-report.json
          safety-report.json
      if: always()

  dependency-update:
    name: Dependency Update Check
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Check for outdated packages
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt
        
        echo "::group::Outdated Packages"
        pip list --outdated --format=json > outdated.json
        python -c "
        import json
        
        try:
            with open('outdated.json', 'r') as f:
                outdated = json.load(f)
            
            if outdated:
                print('📦 Outdated packages found:')
                for pkg in outdated:
                    print(f'  {pkg[\"name\"]}: {pkg[\"version\"]} → {pkg[\"latest_version\"]}')
            else:
                print('✅ All packages are up to date')
        except:
            print('No outdated packages found')
        "
        echo "::endgroup::"
      continue-on-error: true
