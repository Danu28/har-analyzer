# HAR Analysis Tools for AI Agents

This directory contains Python tools specifically designed for AI agents to analyze HAR (HTTP Archive) files efficiently.

## ğŸ› ï¸ Available Tools

### 1. `quick_analyze.py` - Fast Analysis
**Best for**: Quick performance overview and agent consumption

```bash
python quick_analyze.py
```

**Features**:
- âœ… Auto-detects HAR files in current directory or `HAR-Files/` subdirectory
- âœ… Provides immediate performance grade (GOOD/FAIR/POOR/CRITICAL)
- âœ… Shows key metrics: load time, requests, size, failures
- âœ… Outputs structured JSON for easy parsing
- âœ… No file breakdown required (works directly with large HAR files)

**Output**: `quick_analysis_<filename>.json`

### 2. `break_har_file.py` - Detailed Breakdown
**Best for**: Comprehensive analysis and large file handling

```bash
python break_har_file.py
```

**Features**:
- âœ… Breaks large HAR files into manageable chunks
- âœ… Auto-detects HAR files in current directory
- âœ… Creates organized output in `har_chunks/` directory
- âœ… Generates resource type files, summaries, and guides
- âœ… Enables detailed analysis of massive HAR files

**Output**: `har_chunks/<filename>/` directory with 30+ analysis files

### 3. `analyze_performance.py` - Advanced Analysis
**Best for**: Deep performance analysis and recommendations

```bash
python analyze_performance.py
```

**Features**:
- âœ… Comprehensive performance metrics
- âœ… Critical path analysis
- âœ… Third-party service impact assessment
- âœ… Resource type performance breakdown
- âœ… Automated recommendations
- âœ… Agent-friendly JSON summary

**Output**: Console output + `agent_summary.json`

### 4. **HAR Comparison Flow** ğŸ†• - Compare Two HAR Files
**Best for**: Performance regression detection and A/B testing

```bash
# Quick demo with available files
python demo_har_comparison.py --demo

# Compare specific files
python demo_har_comparison.py --base baseline.har --target current.har
```

**Features**:
- âœ… **Complete Workflow**: Break â†’ Analyze â†’ Report in one command
- âœ… **Performance Regression Detection**: Automatically identifies slowdowns
- âœ… **Resource Delta Analysis**: Shows added, removed, modified resources
- âœ… **Professional HTML Reports**: Interactive comparison reports
- âœ… **KPI Tracking**: Load time, request count, size changes
- âœ… **Third-party Impact**: Domain-level analysis
- âœ… **CI/CD Ready**: JSON output for automation

**Output**: 
- `comparison_analysis.json` - Structured comparison data
- `comparison_report.html` - Interactive visual report
- Individual breakdown files for base and target

**Use Cases**:
- Before/after code deployment comparisons
- Performance impact of new features
- A/B testing different configurations
- Environment comparison (staging vs production)

**Documentation**: See `HAR_COMPARISON_GUIDE.md` for detailed usage

## ğŸ¤– Agent Usage Patterns

### For Quick Assessment
```python
# Run quick analysis
result = subprocess.run(['python', 'quick_analyze.py'], capture_output=True, text=True)
# Parse the generated JSON file
with open('quick_analysis_<filename>.json') as f:
    data = json.load(f)
```

### For Detailed Analysis
```python
# 1. Break down the HAR file
subprocess.run(['python', 'break_har_file.py'])
# 2. Run detailed analysis
subprocess.run(['python', 'analyze_performance.py'])
# 3. Read agent summary
with open('har_chunks/<filename>/agent_summary.json') as f:
    detailed_data = json.load(f)
```

### For HAR Comparison
```python
# 1. Run HAR comparison demo
subprocess.run(['python', 'demo_har_comparison.py', '--demo'])
# 2. Compare specific HAR files
subprocess.run(['python', 'demo_har_comparison.py', '--base', 'baseline.har', '--target', 'current.har'])
# 3. Access comparison results
with open('comparison_analysis.json') as f:
    comparison_data = json.load(f)
```

## ğŸ“Š Understanding the Output

### Performance Grades
- **GOOD**: Load time < 3 seconds
- **FAIR**: Load time 3-5 seconds  
- **POOR**: Load time 5-10 seconds
- **CRITICAL**: Load time > 10 seconds

### Key Metrics
- **Total Requests**: Number of network requests (target: < 100)
- **Page Load Time**: Time until `onLoad` event
- **DOM Ready Time**: Time until `DOMContentLoaded` event
- **Failed Requests**: HTTP status codes 400+
- **Slow Requests**: Individual requests taking > 1 second

## ğŸ”§ Troubleshooting

### Common Issues
1. **No HAR files found**: Place `.har` files in current directory or `HAR-Files/` subdirectory
2. **Large file errors**: Use `break_har_file.py` first to handle files > 50MB
3. **Missing analysis data**: Run `break_har_file.py` before `analyze_performance.py`

### Directory Structure
```
HAR-analyze/
â”œâ”€â”€ quick_analyze.py          # Quick analysis tool
â”œâ”€â”€ break_har_file.py         # HAR file breakdown tool
â”œâ”€â”€ analyze_performance.py    # Advanced analysis tool
â”œâ”€â”€ demo_har_comparison.py    # HAR comparison demo tool
â”œâ”€â”€ HAR-Files/                # Place HAR files here
â”‚   â””â”€â”€ your_file.har
â””â”€â”€ har_chunks/               # Generated analysis files
    â””â”€â”€ your_file/
        â”œâ”€â”€ agent_summary.json
        â”œâ”€â”€ 01_header_and_metadata.json
        â””â”€â”€ ...
```

## ğŸ“ˆ Sample Agent Summary JSON

```json
{
  "performance_summary": {
    "total_requests": 173,
    "dom_ready_time": "43.26s",
    "page_load_time": "56.36s",
    "performance_grade": "CRITICAL"
  },
  "critical_issues": {
    "very_slow_requests": 69,
    "slow_requests": 29,
    "failed_requests": 1,
    "excessive_requests": true
  },
  "largest_assets": [
    {
      "url": "https://example.com/large-bundle.js",
      "size_kb": 31609.4
    }
  ],
  "failed_requests": [
    {
      "url": "https://broken-resource.com/script.js",
      "status": 403
    }
  ]
}
```

## ğŸš€ Quick Start for Agents

1. **Place HAR file** in `HAR-Files/` directory
2. **Run quick analysis**: `python quick_analyze.py`
3. **Check performance grade** in the output
4. **For detailed analysis**: Run `python break_har_file.py` then `python analyze_performance.py`
5. **Parse JSON output** for structured data

The tools are designed to be robust, automatic, and provide consistent JSON output suitable for programmatic consumption by AI agents.
